{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import json\n",
    "import re\n",
    "import itertools\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading data\")\n",
    "erb = pd.read_csv(\"../data/raw/erb_translators.tsv\", sep=\"\\t\", encoding=\"utf8\").convert_dtypes()\n",
    "\n",
    "with open(\"../data/roles.json\", \"r\", encoding=\"utf8\") as f:\n",
    "    roles = json.load(f)\n",
    "    roles_compact = list(set(roles.values()))\n",
    "\n",
    "with open(\"../data/genres.json\", \"r\", encoding=\"utf8\") as f:\n",
    "    genres = json.load(f)\n",
    "    fiction = genres[\"fiction\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_person_info(person_str):\n",
    "    # Remove any titles enclosed in quotes\n",
    "    person_str = re.sub(r': \".*?\"', '', person_str)\n",
    "\n",
    "    # Regular expression patterns\n",
    "    pattern_with_role = r'^(.+?) \\(([\\d?]+)?-([\\d?]+)?\\) \\[([\\w\\s]+)\\]$'\n",
    "    pattern_only_date = r'^(.+?) \\(([\\d?]+)?-([\\d?]+)?\\)$'\n",
    "    pattern_only_role = r'^(.+?) \\[([\\w\\s]+)\\]$'\n",
    "    pattern_name_only = r'^(.+?)$'\n",
    "\n",
    "    # Extract name, birth dates, and role\n",
    "    match = re.match(pattern_with_role, person_str)\n",
    "    if match:\n",
    "        name, birth_date, death_date, role = match.groups()\n",
    "        birth_date = birth_date or \"0000\"\n",
    "        death_date = death_date or \"9999\"\n",
    "        return name.strip(), (birth_date, death_date), role.strip().lower()\n",
    "    \n",
    "    # Handle the case where the role is missing but date exists\n",
    "    match = re.match(pattern_only_date, person_str)\n",
    "    if match:\n",
    "        name, birth_date, death_date = match.groups()\n",
    "        birth_date = birth_date or \"0000\"\n",
    "        death_date = death_date or \"9999\"\n",
    "        return name.strip(), (birth_date, death_date), None\n",
    "    \n",
    "    # Handle the case where the date is missing but role exists\n",
    "    match = re.match(pattern_only_role, person_str)\n",
    "    if match:\n",
    "        name, role = match.groups()\n",
    "        return name.strip(), (\"0000\", \"9999\"), role.strip().lower()\n",
    "\n",
    "    # Handle the case where only the name exists\n",
    "    match = re.match(pattern_name_only, person_str)\n",
    "    if match:\n",
    "        name = match.group(1)\n",
    "        return name.strip(), (\"0000\", \"9999\"), None\n",
    "\n",
    "    # Return an error if no pattern matched\n",
    "    print(f\"Error: '{person_str}' doesn't match expected patterns.\")\n",
    "    return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tidy_translators(contributors):\n",
    "    contributors = contributors.replace(\"; \", \";\").split(\";\")\n",
    "    translators = []\n",
    "    for person in contributors:\n",
    "        if extract_person_info(person)[2] == \"tõlkija\":\n",
    "            translators.append(person)\n",
    "\n",
    "    return translators\n",
    "\n",
    "# sample = 'Novikov, Kadi [tõlkija]; Lillemäe, Karolin [tõlkija]; Kaibald, Peegi [tõlkija]; Bauer, Annika (1976-) [toimetaja]; Garshnek, Jan (1981-) [kujundaja]'\n",
    "# tidy_translators(sample)\n",
    "\n",
    "erb[\"translators\"] = erb.contributor.apply(tidy_translators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_translations_graph(erb, timerange, min_count=1, only_living=True, only_to_estonian=False, allowed_genres=None):\n",
    "    \"\"\"\n",
    "    Create a graph based on the provided dataframe `erb` within a given `timerange`.\n",
    "    Nodes represent authors, and edges represent co-authorship.\n",
    "    \"\"\"\n",
    "\n",
    "    # Filter the dataframe based on timerange and existence of creator or contributor\n",
    "    df = erb.loc[(erb.year >= timerange[0]) & (erb.year <= timerange[-1])]\n",
    "    df = df.loc[(df.creator.notna()) & (df.translators.notna())]\n",
    "    if only_to_estonian:\n",
    "        df = df.loc[df.language_original != \"est\"]\n",
    "    if allowed_genres:\n",
    "        df = df.loc[df.subject_genre.notna()].copy()\n",
    "        mask = df.subject_genre.str.replace(\"; \", \";\").str.split(\";\").apply(lambda x: any(g in allowed_genres for g in x))\n",
    "        df = df[mask]\n",
    "\n",
    "    G = nx.Graph()\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        # Extract and process person data from the dataframe row\n",
    "        creators = [extract_person_info(name.strip()) for name in row['creator'].split(';') if name.strip() != '']\n",
    "        translators = [extract_person_info(person) for person in row[\"translators\"]]\n",
    "        people = creators + translators\n",
    "        pairs = list(itertools.product([p[0] for p in creators], [p[0] for p in translators]))\n",
    "        #print(pairs)\n",
    "\n",
    "        for pair in pairs:\n",
    "            current_year = row['year']  # The year of the current publication\n",
    "            \n",
    "            if G.has_edge(pair[0], pair[1]):\n",
    "                G[pair[0]][pair[1]]['weight'] += 1\n",
    "                G[pair[0]][pair[1]]['works'].append((row['title'], current_year, current_year))\n",
    "                G[pair[0]][pair[1]][\"languages\"].append(row[\"language_original\"])    # LANGUAGE\n",
    "                \n",
    "                # Update the activity_end for the edge\n",
    "                G[pair[0]][pair[1]]['activity_end'] = max(G[pair[0]][pair[1]].get('activity_end', current_year), current_year)\n",
    "                \n",
    "                # Ensure the activity_start is the smallest value\n",
    "                G[pair[0]][pair[1]]['activity_start'] = min(G[pair[0]][pair[1]].get('activity_start', current_year), current_year)\n",
    "                \n",
    "            else:\n",
    "                G.add_edge(pair[0], pair[1], weight=1, activity_start=current_year, activity_end=current_year)\n",
    "                G[pair[0]][pair[1]]['works'] = [(row['title'], current_year, current_year)]\n",
    "                G[pair[0]][pair[1]][\"languages\"] = [row[\"language_original\"]]\n",
    "\n",
    "        # Process nodes (authors)\n",
    "        for person in people:\n",
    "            name, dates, role = person\n",
    "            if G.has_node(name):\n",
    "                if role:\n",
    "                    if role in roles.keys():\n",
    "                        role_count_key = f\"{roles[role]}_count\"\n",
    "                    else:\n",
    "                        role_count_key = \"muu_count\"\n",
    "                    G.nodes[name][role_count_key] = G.nodes[name].get(role_count_key, 0) + 1\n",
    "                G.nodes[name]['activity_end'] = max(G.nodes[name].get('activity_end', row['year']), row['year'])\n",
    "                G.nodes[name]['activity_start'] = min(G.nodes[name].get('activity_start', row['year']), row['year'])\n",
    "            else:\n",
    "                node_attrs = {\n",
    "                    'date_of_birth': int(dates[0]) if dates[0].isnumeric() else dates[0],\n",
    "                    'date_of_death': int(dates[1]) if dates[1].isnumeric() else dates[1],\n",
    "                    'activity_start': row['year'],\n",
    "                    'activity_end': row['year']\n",
    "                }\n",
    "                if role:\n",
    "                    node_attrs[f\"{roles[role]}_count\"] = 1\n",
    "                G.add_node(name, **node_attrs)\n",
    "\n",
    "    # Remove self-loops (if any)\n",
    "    G.remove_edges_from(list(nx.selfloop_edges(G)))\n",
    "\n",
    "    # Calculate and store the total_count for each node, define the main role\n",
    "    for name, attributes in G.nodes(data=True):\n",
    "        node_roles = dict(zip(roles_compact, [attributes.get(f\"{role}_count\", 0) for role in roles_compact]))\n",
    "        G.nodes[name][\"total_count\"] = sum(node_roles.values())\n",
    "        G.nodes[name][\"main_role\"] = max(node_roles, key=node_roles.get)\n",
    "        \n",
    "        if G.nodes[name][\"main_role\"] == \"autor\":\n",
    "            G.nodes[name][\"author_lang\"] = df.loc[df.creator.str.contains(name, regex=False)].language_original.mode().values[0]\n",
    "        elif G.nodes[name][\"main_role\"] == \"tõlkija\":\n",
    "            G.nodes[name][\"author_lang\"] = \"tõlkija\"\n",
    "        else:\n",
    "            G.nodes[name][\"author_lang\"] = \"other\"\n",
    "\n",
    "        # Limit years active to period when the author was alive\n",
    "        if only_living:\n",
    "            if \"date_of_death\" in G.nodes[name] and type(G.nodes[name][\"date_of_death\"]) == int:\n",
    "                G.nodes[name][\"activity_end\"] = min(G.nodes[name][\"date_of_death\"], G.nodes[name][\"activity_end\"])\n",
    "\n",
    "    # Set the proportion of Estonian works in each edge\n",
    "    for edge in G.edges:\n",
    "        G.edges[edge][\"language\"] = Counter(G.edges[edge][\"languages\"]).most_common(1)[0][0]\n",
    "        G.edges[edge].pop(\"languages\")\n",
    "\n",
    "    # Remove nodes below the specified min_count\n",
    "    if min_count > 1:\n",
    "        nodes_to_remove = [node for node, attributes in G.nodes(data=True) if attributes['total_count'] < min_count]\n",
    "        G.remove_nodes_from(nodes_to_remove)\n",
    "\n",
    "    print(f\"Created graph with {len(G.nodes)} nodes and {len(G.edges)} edges\")\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created graph with 456 nodes and 335 edges\n"
     ]
    }
   ],
   "source": [
    "G = create_translations_graph(erb, timerange=range(1900, 1910), min_count=1,\n",
    "                              only_living=False, only_to_estonian=True, allowed_genres=fiction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in G.nodes():\n",
    "    for key, val in G.nodes()[node].items():\n",
    "        if type(val) not in [str, int, float]:\n",
    "            print(node, key, val, type(val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'autor_count': 23,\n",
       " 'activity_end': 1908,\n",
       " 'activity_start': 1904,\n",
       " 'total_count': 23,\n",
       " 'main_role': 'autor',\n",
       " 'author_lang': 'rus'}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.nodes()[\"Tolstoi, Lev\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_gexf(G, \"../data/gephi/translators_1500_2025_fiction.gexf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
